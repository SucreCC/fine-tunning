# ========================
# 服务配置
# ========================
service:
  service_name: mu_xue
  description: mu_xue
  version: 1.0.0

log:
  service_name: mu_xue
  log_dir: ./logs
  log_file: ./logs/mu_xue.log
  error_file: ./logs/mu_xue.error.log
  log_level: INFO
  uvicorn_log_level: INFO
  uvicorn_access_log_level: WARNING
  sqlalchemy_log_level: WARNING
  log_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"

# ========================
# 模型配置
# ========================
model:
  base_model_path: "./model/Qwen2.5-7B-Instruct"
  output_dir: "./outputs/checkpoints"

  # 量化配置（为 QLoRA / LoRA 预留）
  quantization:
    enable: false
    bits: 4                # 4 | 8
    compute_dtype: bf16    # fp16 | bf16

# ========================
# 微调策略配置（核心）
# ========================
finetune:
  strategy: lora           # full | lora | qlora | prefix_tuning | p_tuning | adalora | ia3
  stage: sft               # sft | dpo | rm（先预留）
  
  # LoRA / QLoRA 配置（strategy=lora / qlora 时生效）
  lora:
    enable: true
    r: 8
    lora_alpha: 32
    target_modules: ["q_proj", "v_proj"]
    lora_dropout: 0.1
    bias: "none"
  
  # Prefix Tuning 配置（strategy=prefix_tuning 时生效）
  prefix_tuning:
    enable: true
    num_virtual_tokens: 20
    encoder_hidden_size: null  # null 表示使用模型隐藏层维度
    prefix_projection: false
    task_type: "CAUSAL_LM"
  
  # P-Tuning 配置（strategy=p_tuning / ptuning 时生效）
  p_tuning:
    enable: true
    num_virtual_tokens: 20
    encoder_hidden_size: null
    encoder_num_layers: 2
    encoder_reparameterization_type: "MLP"  # MLP | LSTM
    task_type: "CAUSAL_LM"
  
  # AdaLoRA 配置（strategy=adalora 时生效）
  adalora:
    enable: true
    r: 8
    lora_alpha: 32
    target_modules: ["q_proj", "v_proj"]
    lora_dropout: 0.1
    init_r: 12
    target_r: 8
    beta1: 0.85
    beta2: 0.85
    task_type: "CAUSAL_LM"
    bias: "none"
  
  # IA3 配置（strategy=ia3 时生效）
  ia3:
    enable: true
    target_modules: ["k_proj", "v_proj", "out_proj"]
    feedforward_modules: []
    task_type: "CAUSAL_LM"

# ========================
# 数据集配置
# ========================
dataset:
  train_path: "./dataset/moemuu/raw/train.jsonl"
  val_path: "./dataset/moemuu/raw/test.jsonl"
  max_length: 2048
  streaming: false
  train_ratio: 1.0

  # Processor（你设计得很好，保留）
  processor:
    type: qwen
    system_prompt: |
      你是一个名为沐雪的可爱AI女孩子。
      你是一个角色扮演的角色。

# ========================
# 训练参数
# ========================
training:
  num_epochs: 3
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  learning_rate: 2.0e-5
  weight_decay: 0.01
  lr_scheduler_type: cosine
  warmup_steps: 100
  save_steps: 500
  eval_steps: 500
  logging_steps: 50
  seed: 42
  max_grad_norm: 1.0

  precision:
    fp16: true
    bf16: false


# ========================
# WandB 配置
# ========================
wandb:
  use_wandb: false
  wandb_api_key: null
  wandb_project: "mu_xue_finetuning"
  wandb_run_name: null
  wandb_entity: null
  wandb_tags: null
  wandb_dir: null