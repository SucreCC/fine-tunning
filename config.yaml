# ========================
# 服务配置
# ========================
service:
  service_name: mu_xue
  description: mu_xue
  version: 1.0.0

log:
  service_name: mu_xue
  log_dir: ./logs
  log_file: ./logs/mu_xue.log
  error_file: ./logs/mu_xue.error.log
  log_level: INFO
  uvicorn_log_level: INFO
  uvicorn_access_log_level: WARNING
  sqlalchemy_log_level: WARNING
  log_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  date_format: "%Y-%m-%d %H:%M:%S"

# ========================
# WandB 配置
# ========================
wandb:
  use_wandb: true
  wandb_api_key: "f49fecc68453c53efcf05f3eef1ed2baddb92036"
  wandb_project: "mu_xue_finetuning"
  wandb_run_name: "Qwen2.5-7B-Instruct"
  wandb_entity: null
  wandb_tags: null
  wandb_dir: null

# ========================
# 模型配置
# ========================
model:
  base_model_path: "./model/Qwen2.5-7B-Instruct"
  # 检查点基础目录（所有检查点的根目录）
  checkpoint_dir: "./outputs/checkpoints"
  # 运行名称/实验名称（会在 checkpoint_dir 下创建以此命名的子目录）
  # 如果不设置，则自动从 wandb.wandb_run_name 获取
  # run_name: 自动从 wandb.wandb_run_name 获取，无需手动设置
  # output_dir: 已废弃，使用 checkpoint_dir + run_name 代替
  # 如果设置了 checkpoint_dir 和 run_name，output_dir 会被忽略

  # 量化配置（为 QLoRA / LoRA 预留）
  quantization:
    enable: false
    bits: 4                # 4 | 8
    compute_dtype: bf16    # fp16 | bf16

# ========================
# 微调策略配置（核心）
# ========================
finetune:
  type: lora           # full | qlora | prefix_tuning | p_tuning | adalora | ia3
  stage: sft               # sft | dpo | rm（先预留）
  enable: true
  
  # Prefix Tuning 配置（type=prefix_tuning 时生效）
  prefix_tuning:
    num_virtual_tokens: 20
    encoder_hidden_size: null  # null 表示使用模型隐藏层维度
    prefix_projection: false
    task_type: "CAUSAL_LM"
  
  # P-Tuning 配置（type=p_tuning / ptuning 时生效）
  p_tuning:
    num_virtual_tokens: 20
    encoder_hidden_size: null
    encoder_num_layers: 2
    encoder_reparameterization_type: "MLP"  # MLP | LSTM
    task_type: "CAUSAL_LM"
  
  # LoRA 配置（type=lora / qlora 时生效）
  lora:
    r: 8
    lora_alpha: 32
    target_modules: ["q_proj", "v_proj"]
    lora_dropout: 0.1
    init_r: 12
    target_r: 8
    beta1: 0.85
    beta2: 0.85
    task_type: "CAUSAL_LM"
    bias: "none"
  
  # IA3 配置（type=ia3 时生效）
  ia3:
    target_modules: ["k_proj", "v_proj", "out_proj"]
    feedforward_modules: []
    task_type: "CAUSAL_LM"

# ========================
# 数据集配置
# ========================
dataset:
  train_path: "./dataset/moemuu/raw/train.jsonl"
  val_path: "./dataset/moemuu/raw/test.jsonl"
  max_length: 2048
  streaming: false
  train_ratio: 1.0

  # Processor（你设计得很好，保留）
  processor:
    type: qwen
    system_prompt: |
      你是一个名为沐雪的可爱AI女孩子。
      你是一个角色扮演的角色。

# ========================
# 训练参数
# ========================
training:
  num_epochs: 3
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  learning_rate: 2.0e-5
  weight_decay: 0.01
  lr_scheduler_type: cosine
  warmup_steps: 50
  save_steps: 50
  eval_steps: 50
  logging_steps: 5
  seed: 42
  max_grad_norm: 1.0

  precision:
    fp16: true
    bf16: false

  # 设备配置
  device:
    # 设备类型（"cpu" | "gpu" | "tpu" | null）
    # - "cpu": 强制使用 CPU
    # - "gpu": 强制使用 GPU（CUDA）
    # - "tpu": 强制使用 TPU（需要额外配置）
    # - null: 自动检测（优先使用 GPU，如果没有则使用 CPU）
    device_type: cpu  # null | cpu | gpu | tpu
    # 并行策略（"ddp" | "deepspeed" | "fsdp" | null）
    # - "ddp": DistributedDataParallel，单机多卡或多机多卡（推荐用于单机多卡）
    # - "deepspeed": DeepSpeed ZeRO，需要 deepspeed 配置文件（推荐用于大模型）
    # - "fsdp": Fully Sharded Data Parallel，PyTorch FSDP（推荐用于超大模型）
    # - null: 不使用并行（单卡训练）
    parallel_strategy: null  # null | ddp | deepspeed | fsdp
    # 分布式训练后端（当 parallel_strategy="ddp" 时使用）
    # "nccl" 用于多 GPU，"gloo" 用于 CPU，null 表示自动选择
    ddp_backend: null  # null | nccl | gloo
    # DDP 是否查找未使用的参数（用于调试，通常设为 false）
    ddp_find_unused_parameters: false
    # DDP 超时时间（秒）
    ddp_timeout: 1800
    # 本地 rank（分布式训练中当前进程使用的本地 GPU 编号，如 0, 1, 2...）
    # 通常不需要手动设置，会自动从环境变量 LOCAL_RANK 获取（由 torchrun 自动设置）
    # 只有在特殊情况下才需要手动指定
    local_rank: null
    # 指定使用哪些 GPU（例如："0,1" 表示使用 GPU 0 和 1，"0" 表示只使用 GPU 0）
    # 通过设置 CUDA_VISIBLE_DEVICES 环境变量实现
    # 示例：CUDA_VISIBLE_DEVICES=0,1 torchrun --nproc_per_node=2 train.py
    # 注意：这里只是说明，实际使用时通过环境变量设置，不在这里配置
    # DeepSpeed 配置文件路径（当 parallel_strategy="deepspeed" 时使用）
    # 可以是相对路径或绝对路径，也可以从环境变量 DEEPSPEED_CONFIG_FILE 获取
    deepspeed_config: null
    # FSDP 配置（当 parallel_strategy="fsdp" 时使用）
    # 如果为 null，将使用默认配置
    fsdp_config: null


